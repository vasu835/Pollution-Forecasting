{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KHNThuwfQj7p",
        "outputId": "ac61acd7-efce-4a7c-b9a4-4f884a034dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Preprocessing Complete:\n",
            "- `scaled_df`: for LSTM or deep learning models (scaled multivariate time series)\n",
            "- `rf_df`: for Random Forest (tabular with lag features)\n",
            "- `df['pollution']`: for univariate ARIMA models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1-137402542.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['pollution'].fillna(0, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"LSTM-Multivariate_pollution.csv\")\n",
        "\n",
        "# 1. Date Parsing & Indexing\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "\n",
        "# 2. Imputation of Missing Values replace missing values in pollution column with 0\n",
        "df['pollution'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# 3. Feature Removal as observed from visualization, 'wnd_dir' has no strong numerical relationship with pollution.\n",
        "df.drop(columns=['wnd_dir'], inplace=True)\n",
        "\n",
        "# 4. Feature Selection\n",
        "selected_features = ['dew', 'temp', 'press', 'wnd_spd', 'rain', 'snow', 'pollution']\n",
        "df = df[selected_features]\n",
        "\n",
        "# 6. Scaling (for LSTM) in the range of [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=df.columns, index=df.index)\n",
        "\n",
        "# 7. Lag Feature for random forest\n",
        "def add_lag_features(data, target='pollution', lags=3):\n",
        "    data_with_lags = data.copy()\n",
        "    for lag in range(1, lags + 1):\n",
        "        data_with_lags[f'{target}_lag{lag}'] = data_with_lags[target].shift(lag)\n",
        "    return data_with_lags.dropna()\n",
        "\n",
        "# Used for Random Forest or XGBoost\n",
        "rf_df = add_lag_features(df.copy())\n",
        "\n",
        "# 8. Outputs\n",
        "print(\"✅ Preprocessing Complete:\")\n",
        "print(\"- `scaled_df`: for LSTM or deep learning models (scaled multivariate time series)\")\n",
        "print(\"- `rf_df`: for Random Forest (tabular with lag features)\")\n",
        "print(\"- `df['pollution']`: for univariate ARIMA models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "5x9McXdTSihc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing modules needed for this model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Prepare sequences for LSTM\n",
        "n_past = 24  # past 24 hours\n",
        "n_future = 1  # next hour prediction\n",
        "\n",
        "X, y = [], []\n",
        "for i in range(n_past, len(scaled_df) - n_future + 1):\n",
        "    X.append(scaled_df.iloc[i - n_past:i].values)\n",
        "    y.append(scaled_df.iloc[i + n_future - 1]['pollution'])\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "E5jtkyrSSkQy",
        "outputId": "74056213-dcef-4aca-9dde-cf4da22c54a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0060 - val_loss: 7.6292e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 6.4172e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.4599e-04 - val_loss: 6.1771e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 8.2211e-04 - val_loss: 6.1020e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 8.8329e-04 - val_loss: 6.0134e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 7.8857e-04 - val_loss: 5.6426e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 9.8592e-04 - val_loss: 5.2923e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 8.4881e-04 - val_loss: 5.5967e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 8.2015e-04 - val_loss: 5.1225e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 8.7208e-04 - val_loss: 5.1186e-04\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "Root Mean Squared Error (RMSE): 0.02408716492736944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "q1hAZ6cKS754"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing modules needed for this model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Create lag features (use past 3 hours)\n",
        "def add_lag_features(data, target='pollution', lags=3):\n",
        "    for lag in range(1, lags + 1):\n",
        "        data[f'{target}_lag{lag}'] = data[target].shift(lag)\n",
        "    return data.dropna()\n",
        "\n",
        "rf_df = add_lag_features(df.copy())\n",
        "\n",
        "# Define X and y\n",
        "X = rf_df.drop(columns=['pollution'])\n",
        "y = rf_df['pollution']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
        "\n",
        "# Train Random Forest model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Show feature importances (optional)\n",
        "importances = model.feature_importances_\n",
        "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"✅ Random Forest RMSE:\", rmse)\n",
        "print(\"\\nTop Features:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WkXn0XNlS5yD",
        "outputId": "22b6436d-4137-4431-f52c-207be3c56048"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Random Forest RMSE: 23.948320878022166\n",
            "\n",
            "Top Features:\n",
            "          Feature  Importance\n",
            "6  pollution_lag1    0.919107\n",
            "7  pollution_lag2    0.021901\n",
            "8  pollution_lag3    0.015082\n",
            "0             dew    0.012987\n",
            "3         wnd_spd    0.010745\n",
            "1            temp    0.009221\n",
            "2           press    0.008870\n",
            "4            rain    0.001869\n",
            "5            snow    0.000216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ARIMA**"
      ],
      "metadata": {
        "id": "pPtiRlQLUngk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing modules needed for this model\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"LSTM-Multivariate_pollution.csv\")\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "\n",
        "# Use only the target variable\n",
        "pollution_series = df['pollution'].fillna(0)\n",
        "\n",
        "# Split into train/test (80/20)\n",
        "train_size = int(len(pollution_series) * 0.8)\n",
        "train, test = pollution_series[:train_size], pollution_series[train_size:]\n",
        "\n",
        "# Fit ARIMA model (p=5, d=1, q=2 is a common starting point; use grid search for optimal)\n",
        "model = ARIMA(train, order=(5, 1, 2))\n",
        "model_fit = model.fit()\n",
        "\n",
        "# Forecast\n",
        "forecast = model_fit.forecast(steps=len(test))\n",
        "rmse = np.sqrt(mean_squared_error(test, forecast))\n",
        "\n",
        "print(\"✅ ARIMA RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RoNSIBSmUk9g",
        "outputId": "1a83294d-f5ae-4cb8-a40f-2a296488cc45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ARIMA RMSE: 93.67847467359053\n"
          ]
        }
      ]
    }
  ]
}